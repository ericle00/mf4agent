import streamlit as st
from typing import List
import json

from lagent import BaseAgent, BaseAction, BaseModel
from lagent.actions import ActionExecutor
from lagent.schema import AgentReturn, ActionStatusCode, ActionReturn

from agent.actions.ipython_interpreter import IPythonInterpreter

from agent.actions.planning import PlanningAction
from agent.actions.role_coder_selecting import RoleCoderSelectionAction
from agent.actions.coding import CodeGenerationAction

from models.llms.llms import OpenAICoreML

from agent.components.protocol import Protocol
from agent.components.working_memory import WorkingMemory

from gui.styles.chatpage_headers import ChatPageHeader
from gui.keys.gui_input import GUIInput

from utils.text_string import split_string, replace_word
from utils.text_string import extract_and_join_python_blocks


# d888888b d8b   db d888888b d888888b 
#   `88'   888o  88   `88'   `~~88~~' 
#    88    88V8o 88    88       88    
#    88    88 V8o88    88       88    
#   .88.   88  V888   .88.      88    
# Y888888P VP   V8P Y888888P    YP    
                                    
                                    

class Brain(BaseAgent):
    """
    This will be the brain of the model.
    """

    def __init__(self, 
                llm_thinker: OpenAICoreML,
                llm_coder: OpenAICoreML,
                ipython_interpreter: IPythonInterpreter) -> None:
        
        # Initialize protocol, action executor, and working memory
        protocol: object = Protocol()
        action_executor: ActionExecutor = ActionExecutor([])

        super().__init__(llm_thinker, action_executor, protocol)
        
        
        # Initialize own variables
        self.llm_thinker = llm_thinker
        self.llm_coder = llm_coder
        
        ################# Init memory #################
        self.working_memory = WorkingMemory()
        """ Short term memory
            - Stores core information such as active goals. 
            - Stores recent goals and results from the most recent internal reasoning. 
            - Core information from the previous cycle.
            - Active knowledge is generated by reasoning and/or retrieval, and is saved here 
             for one cycle.
        """

        self.procedural = None
        """ Long term memory
            - Two types, implicit and explicit
            - Implicit = Memory stored in the LLM weights
            - Explicit = Knowledge written in the agents code. 
            ----
            Not used! Is only here to describe the different kind of memories.
        """

        self.semantic = None
        """ Long term memory
            - Stores facts about the world. 
            ----
            Note: Thinking of having two sematic memories, document database for the PDFs
            and then other facts that the model has found.
            ----
            This variable is not used! It is only here to describe stuff.
            However, you can access the sematic memory through the `retrieval` action.
        """

        self.episodic = None
        """ Long term memory
            - Stores previous sequences / experiences 
        """

        ################# Init actions #################
        self.actions_used: List[ActionReturn] = []

        # Planning action
        self.planning_action = PlanningAction(llm=llm_thinker)
        self.add_action(self.planning_action)
        
        # Selector action
        self.role_coder_selecting_action = RoleCoderSelectionAction(llm=llm_thinker)
        self.add_action(self.role_coder_selecting_action)
        
        # Code generation action
        self.code_generation_action = CodeGenerationAction(llm=llm_coder)
        self.add_action(self.code_generation_action)
        
        # Code execution action
        self.ipython_interpreter_action = ipython_interpreter
        self.add_action(self.ipython_interpreter_action)
        
        

    # .o88b. db   db  .d8b.  d888888b 
    # d8P  Y8 88   88 d8' `8b `~~88~~' 
    # 8P      88ooo88 88ooo88    88    
    # 8b      88~~~88 88~~~88    88    
    # Y8b  d8 88   88 88   88    88    
    # `Y88P' YP   YP YP   YP    YP    
                                 
    def chat(self, agent_input: dict) -> AgentReturn:
        actions_used = []
        # TODO Error handling between actions
        
        self.agent_input = agent_input

        # Streamlit placeholder for progress
        self.placeholder = st.empty()
        self.actions_index = 0
        self.placeholder_progress_text = "\t"


        # d8888b. db       .d8b.  d8b   db d8b   db d88888b d8888b. 
        # 88  `8D 88      d8' `8b 888o  88 888o  88 88'     88  `8D 
        # 88oodD' 88      88ooo88 88V8o 88 88V8o 88 88ooooo 88oobY' 
        # 88~~~   88      88~~~88 88 V8o88 88 V8o88 88~~~~~ 88`8b   
        # 88      88booo. 88   88 88  V888 88  V888 88.     88 `88. 
        # 88      Y88888P YP   YP VP   V8P VP   V8P Y88888P 88   YD 
                                                  
        # Process update
        progress_step_thinking_text = self._generate_progress_text("Generating plan")        
        with st.spinner(progress_step_thinking_text): 
            # Note
            gui_input, plan_initial_generic, plan_reformatted = self.planner_action_and_progress(agent_input)
            plan_serialized = json.dumps([gui_input, plan_initial_generic])
        


        # .o88b.  .d88b.  d8888b. d88888b      d888888b d8b   db d888888b d88888b d8888b. d8888b. d8888b. d88888b d888888b d88888b d8888b. 
        # d8P  Y8 .8P  Y8. 88  `8D 88'            `88'   888o  88 `~~88~~' 88'     88  `8D 88  `8D 88  `8D 88'     `~~88~~' 88'     88  `8D 
        # 8P      88    88 88   88 88ooooo         88    88V8o 88    88    88ooooo 88oobY' 88oodD' 88oobY' 88ooooo    88    88ooooo 88oobY' 
        # 8b      88    88 88   88 88~~~~~         88    88 V8o88    88    88~~~~~ 88`8b   88~~~   88`8b   88~~~~~    88    88~~~~~ 88`8b   
        # Y8b  d8 `8b  d8' 88  .8D 88.            .88.   88  V888    88    88.     88 `88. 88      88 `88. 88.        88    88.     88 `88. 
        # `Y88P'  `Y88P'  Y8888D' Y88888P      Y888888P VP   V8P    YP    Y88888P 88   YD 88      88   YD Y88888P    YP    Y88888P 88   YD 
                                                                                                                                        

        coder_role = "None"
        code_generated, code_output_text = "", ""
        code_output_image_list = []

        code_action_map = agent_input[GUIInput.CODE_ACTIONS_MAP_KEY]
        show_code = code_action_map[GUIInput.CODE_ACTIONS_SHOW_CODE_KEY]
        run_code = code_action_map[GUIInput.CODE_ACTIONS_RUN_CODE_KEY]
        
        if show_code or run_code :
            # Role code selection
            progress_step_thinking_text = self._generate_progress_text("Selecting role")        
            with st.spinner(progress_step_thinking_text):
                coder_role = self.code_role_selection_action_and_process(agent_input, gui_input, plan_initial_generic)

            
            # Code generation
            progress_step_thinking_text = self._generate_progress_text("Generating code")        
            with st.spinner(progress_step_thinking_text):
                code_generated = self.code_generation_action_and_process(agent_input, gui_input, plan_initial_generic, plan_reformatted, coder_role)

        
        # Run code
        if run_code and code_generated:
            # Code Execution
            progress_step_thinking_text = self._generate_progress_text("Executing code")        
            with st.spinner(progress_step_thinking_text):
                code_run_output, code_run_err_msg = self.code_execution_action_and_process(gui_input, plan_initial_generic, code_generated)
                
            if code_run_err_msg:
                code_output_text = code_run_err_msg
            else:                           
                if code_run_output:
                    for result in code_run_output:
                        content = result.get("content")
                        if result.get("type") == "text":
                            code_output_text = content
                        if result.get("type") == "image":
                            code_output_image_list.append(content)


        # Final answer in the format of serialized the list to a JSON String 
        final_answer_serialized = json.dumps([plan_serialized, code_generated, code_output_text, code_output_image_list])

        # Empty container for temporary messages
        self.placeholder.empty()


        return AgentReturn(
            actions=actions_used,
            response=final_answer_serialized,
        )


    def planner_action_and_progress(self, agent_input: dict) -> list[str]:
        """
        Executes the planning action and updates the progress, generating a plan based on
        the user's query, signal map, system instructions, MF4 file path, and filter conditions.

        Args:
            agent_input (dict): A dictionary containing the user's query, signal map, system
                                instructions, MF4 file path, and filter conditions.

        Returns:
            list[str]: A list containing the GUI input, initial generated plan, and the
                    reformatted plan.
        """
        # Extract relevant components
        user_query = agent_input[GUIInput.USER_QUERY_KEY]
        signal_map = agent_input[GUIInput.SIGNAL_MAP_KEY]
        system_instruction_planner = agent_input[GUIInput.SYSTEM_INSTRUCTION_PLANNER_KEY]
        mf4_filepath = agent_input[GUIInput.MF4_FILE_PATH_KEY]
        filter_conditions = agent_input[GUIInput.FILTER_CONDITION_KEY]
        generation_parameters = agent_input[GUIInput.GENERATION_PARAMETERS_PLANNER_KEY]
        
        # Insert units and back quotes on signals to user query 
        user_query_signals_reformatted = self._insert_signals_and_units_to_user_query(user_query, signal_map)
        
        # Gui input
        gui_input = f"""User query reformatted with signals:\n{user_query_signals_reformatted}\n\n
MF4 filepath:\n{agent_input[GUIInput.MF4_FILE_PATH_KEY]}\n\n
Filter condition:\n{agent_input[GUIInput.FILTER_CONDITION_KEY]}
"""
        # Empty process display 
        self.placeholder.empty()
        
        # Display process
        with self.placeholder.container():
            # Show planner input
            st.markdown(ChatPageHeader.GUI_INPUT)
            st.code(gui_input, language=None)
            self._show_progress_bar(self._process_update("Generating plan"))
    
            # Generate plan
            planning_action_return = self.planning_action.__call__(user_query_signals_reformatted, 
                                                                   system_instruction_planner,
                                                                   generation_parameters)
            plan_initial_generic = planning_action_return.result
                        
            # Reformat plan with mf4 path and filter conditions
            plan_reformatted = self._reformat_query_plan(mf4_filepath, filter_conditions, plan_initial_generic)
            
        return gui_input, plan_initial_generic, plan_reformatted
            
            
    def code_role_selection_action_and_process(self, agent_input: dict, 
                                               gui_input:str, 
                                               plan_initial_generic:str) -> str:
        """
        Executes the code role selection action and updates the process display,
        generating and displaying the coder role based on the user's query and
        the initial plan.

        Args:
            agent_input (dict): A dictionary containing the user's query and other inputs.
            gui_input (str): The formatted GUI input string.
            plan_initial_generic (str): The initial generated plan.

        Returns:
            str: The selected coder role.
        """ 
        # Extract relevant components
        user_query = agent_input[GUIInput.USER_QUERY_KEY]
        
        # Empty process display 
        self.placeholder.empty()
        
        # Display process
        with self.placeholder.container():
            # Display gui input
            st.markdown(ChatPageHeader.GUI_INPUT)
            st.code(gui_input, language=None)
            
            # Display plan 
            st.markdown(ChatPageHeader.GENERIC_PLAN)
            st.code(plan_initial_generic, language=None)
            
            # Show progress
            self._show_progress_bar(self._process_update("Selecting role"))
            
            # Generate and stor coder role
            role_coder_selecting_action_return = self.role_coder_selecting_action.__call__(user_query)
            coder_role = role_coder_selecting_action_return.result
        
        # Return coder role     
        return coder_role
        
        
    def code_generation_action_and_process(self, 
                                           agent_input: dict, 
                                           gui_input: str, 
                                           plan_initial_generic: str , 
                                           plan_reformatted: str, 
                                           coder_role: str) -> str:
        """
        Executes the code generation action and updates the process display,
        generating and displaying the code based on the reformatted plan and
        system instructions for the specified coder role.

        Args:
            agent_input (dict): A dictionary containing the agent's inputs, including the system instruction map.
            gui_input (str): The formatted GUI input string.
            plan_initial_generic (str): The initial generated plan.
            plan_reformatted (str): The reformatted plan.
            coder_role (str): The selected coder role.

        Returns:
            str: The generated code.
        """
        # Extract relevant components
        system_instruction_ci_map = agent_input[GUIInput.SYSTEM_INSTRUCTION_CI_MAP_KEY]
        system_instruction = system_instruction_ci_map[coder_role]
        generation_parameters = agent_input[GUIInput.GENERATION_PARAMETERS_CI_KEY]
        
        # Empty process display 
        self.placeholder.empty()
        with self.placeholder.container():
            # Display gui input
            st.markdown(ChatPageHeader.GUI_INPUT)
            st.code(gui_input, language=None)
            
            # Display plan 
            st.markdown(ChatPageHeader.GENERIC_PLAN)
            st.code(plan_initial_generic, language=None)
            
            # Display process
            self._show_progress_bar(self._process_update("Generating code"))
    
            # Generate and store code
            code_generation_action_return = self.code_generation_action.__call__(plan_reformatted, system_instruction, generation_parameters)
            code_generated = code_generation_action_return.result
        
        # Return code
        return code_generated
        
                
    def code_execution_action_and_process(self, 
                                          gui_input: str, 
                                          plan_initial_generic: str, 
                                          code_generated: str):
        """
        Executes the code and updates the process display, showing the GUI input,
        initial plan, generated code, and the output or error message from the code execution.

        Args:
            gui_input (str): The formatted GUI input string.
            plan_initial_generic (str): The initial generated plan.
            code_generated (str): The generated code to be executed.

        Returns:
            tuple: A tuple containing the code output and error message.
        """
        # Empty process display 
        self.placeholder.empty()
        with self.placeholder.container():
            # Display gui input
            st.markdown(ChatPageHeader.GUI_INPUT)
            st.code(gui_input, language=None)
            
            # Display plan 
            st.markdown(ChatPageHeader.GENERIC_PLAN)
            st.code(plan_initial_generic, language=None)
            
            # Display code
            st.markdown(ChatPageHeader.GENERATED_CODE)
            st.code(extract_and_join_python_blocks(code_generated), language="python", line_numbers=True)
            
            # Display progress
            self._show_progress_bar(self._process_update("Executing code"))
            ipython_interpreter_action_return = self.ipython_interpreter_action.run(command=code_generated)
            
            # Run code and store output
            code_run_output = ipython_interpreter_action_return.result
            code_run_err_msg = ipython_interpreter_action_return.errmsg
            
        # Return code output and error message
        return code_run_output, code_run_err_msg
                                                                                                                          

    def _reformat_query_plan(self, 
                             mf4_filepath: str, 
                             filter_conditions: str,
                             plan: str) -> str:
        """
        Reformats the query plan by incorporating the MF4 file path and filter conditions.

        Args:
            mf4_filepath (str): The file path of the MF4 file.
            filter_conditions (str): The filter conditions to be applied.
            plan (str): The initial plan.

        Returns:
            str: The reformatted query plan including the MF4 file path and filter conditions.
        """
        return f"MF4 filepath: {mf4_filepath}\n\nFilter condition: {filter_conditions} \n\nPlan:\n{plan}"

    
        
    def _insert_signals_and_units_to_user_query(self, 
                                                user_query:str, 
                                                signal_map: dict[str, dict]) -> str:
        """
        Inserts signals and their respective units into the user query.

        Args:
            user_query (str): The original user query.
            signal_map (dict[str, dict]): A dictionary mapping signals to their details, including units.

        Returns:
            str: The user query with signals replaced by their formatted representations, including units.
        """
        user_query_new = user_query
            
        # Signal list
        signal_list = sorted(list(signal_map), key=lambda x: x.lower())
        
        user_query_split_list = list(set(split_string(user_query)))

        # Tokenize user query
        user_query_split_list = split_string(user_query)
        
        for token in user_query_split_list:
            if token in signal_list:
                unit = signal_map[token].get("unit")
                
                if "Not available" in unit:
                    unit = ""

                string_with_unit = f"`{token}` [{unit}]"

                # Replace the signal with signal(units) format
                user_query_new=replace_word(user_query_new, token, string_with_unit)
                            
        return user_query_new
    
    
    
# d8888b. d8888b.  .d88b.   d888b  d8888b. d88888b .d8888. .d8888.      db    db d8888b. d8888b.  .d8b.  d888888b d88888b 
# 88  `8D 88  `8D .8P  Y8. 88' Y8b 88  `8D 88'     88'  YP 88'  YP      88    88 88  `8D 88  `8D d8' `8b `~~88~~' 88'     
# 88oodD' 88oobY' 88    88 88      88oobY' 88ooooo `8bo.   `8bo.        88    88 88oodD' 88   88 88ooo88    88    88ooooo 
# 88~~~   88`8b   88    88 88  ooo 88`8b   88~~~~~   `Y8b.   `Y8b.      88    88 88~~~   88   88 88~~~88    88    88~~~~~ 
# 88      88 `88. `8b  d8' 88. ~8~ 88 `88. 88.     db   8D db   8D      88b  d88 88      88  .8D 88   88    88    88.     
# 88      88   YD  `Y88P'   Y888P  88   YD Y88888P `8888Y' `8888Y'      ~Y8888P' 88      Y8888D' YP   YP    YP    Y88888P 
                                                                                                                        
    def _process_update(self, new_process: str) -> str:
        """
        Updates the progress text with the new process step, marking previous steps as complete.

        Args:
            new_process (str): The new process step to be added to the progress text.

        Returns:
            str: The updated progress text.
        """
        if self.actions_index == 0:
            self.placeholder_progress_text += f"{new_process} ..."
        else:
            self.placeholder_progress_text = self.placeholder_progress_text.replace(f"...", " ✅")
            self.placeholder_progress_text += f" -> {new_process} ..."
        self.actions_index += 1        

        return self.placeholder_progress_text

    def _generate_progress_text(self, new_process: str) -> None:
        """
        Generates progress text indicating the current process step and total actions.

        Args:
            new_process (str): The new process step to be included in the progress text.

        Returns:
            str: The generated progress text including the current step and total actions.
        """
        return f"{new_process} ...⏳ ({self.actions_index+1}/{self.agent_input[GUIInput.N_ACTIONS]})"

        
    def _show_progress_bar(self, progress_text: str) -> None:
        """
        Displays a progress bar with the provided progress text.

        Args:
            progress_text (str): The text to display above the progress bar, indicating the current progress.
        """
        # Display header
        st.markdown(ChatPageHeader.PROGRESS_BAR)
        st.code(progress_text, language=None)
        num = self.actions_index if self.actions_index == 1 else self.actions_index - 1
        
        # Display progress bar
        n_actions = max(1, self.agent_input[GUIInput.N_ACTIONS])
        st.progress(num/n_actions)
